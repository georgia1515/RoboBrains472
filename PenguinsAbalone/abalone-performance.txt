
****************************************
Model: Top-MLP Abalone
Confusion Matrix:
[[ 26  47 269]
 [  0 236  68]
 [ 23  88 288]]
Classification Report:
              precision    recall  f1-score   support

           F       0.53      0.08      0.13       342
           I       0.64      0.78      0.70       304
           M       0.46      0.72      0.56       399

    accuracy                           0.53      1045
   macro avg       0.54      0.52      0.46      1045
weighted avg       0.53      0.53      0.46      1045

Accuracy: 0.5263
Macro-average F1: 0.4649
Weighted-average F1: 0.4617
****************************************

--- Base-DT ---
accuracy_mean: 0.5368
accuracy_var: 0.0000
macro_f1_mean: 0.5318
macro_f1_var: 0.0000
weighted_f1_mean: 0.5256
weighted_f1_var: 0.0000

--- Top-DT ---
accuracy_mean: 0.5368
accuracy_var: 0.0000
macro_f1_mean: 0.5318
macro_f1_var: 0.0000
weighted_f1_mean: 0.5256
weighted_f1_var: 0.0000

--- Base-MLP ---
accuracy_mean: 0.4970
accuracy_var: 0.0000
macro_f1_mean: 0.4014
macro_f1_var: 0.0000
weighted_f1_mean: 0.4024
weighted_f1_var: 0.0000

--- Top-MLP ---
accuracy_mean: 0.5244
accuracy_var: 0.0001
macro_f1_mean: 0.5033
macro_f1_var: 0.0003
weighted_f1_mean: 0.4897
weighted_f1_var: 0.0002
