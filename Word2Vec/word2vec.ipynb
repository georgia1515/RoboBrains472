{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods\n",
    "def select_answer(model, guess, choice1, choice2, choice3, choice4):\n",
    "    choices = [choice1, choice2, choice3, choice4]\n",
    "    if choice1 in model:\n",
    "        choice1_similarity = model.similarity(guess, choice1)\n",
    "    else:\n",
    "        choice1_similarity = 0\n",
    "    \n",
    "    if choice2 in model:\n",
    "        choice2_similarity = model.similarity(guess, choice2)\n",
    "    else:\n",
    "        choice2_similarity = 0\n",
    "    \n",
    "    if choice3 in model:\n",
    "        choice3_similarity = model.similarity(guess, choice3)\n",
    "    else:\n",
    "        choice3_similarity = 0\n",
    "    \n",
    "    if choice4 in model:\n",
    "        choice4_similarity = model.similarity(guess, choice4)\n",
    "    else:\n",
    "        choice4_similarity = 0\n",
    "    \n",
    "    similarity = [choice1_similarity, choice2_similarity, choice3_similarity, choice4_similarity]\n",
    "    \n",
    "    answer = similarity.index(max(similarity))\n",
    "    final_choice = choices[answer]\n",
    "    return final_choice\n",
    "\n",
    "def random_guess(choice1, choice2, choice3, choice4):\n",
    "    choices = [choice1, choice2, choice3, choice4]\n",
    "    return choices[random.randint(0,3)]\n",
    "\n",
    "def create_model_details(model_name):\n",
    "    with open(model_name, 'w+') as f:\n",
    "        writer = csv.writer(f)\n",
    "        field = ['question', 'answer', 'guess', 'label']\n",
    "        writer.writerow(field)\n",
    "\n",
    "def test_model(model_name, model, questions, answers, choice1, choice2, choice3, choice4):\n",
    "    correct_guesses = 0\n",
    "    random_guesses = 0\n",
    "\n",
    "    for i in range(len(questions)):\n",
    "        question = questions[i]\n",
    "        answer = answers[i]\n",
    "        \n",
    "        if question in model:\n",
    "            guess = model.most_similar(question)[0][0]\n",
    "            choice = select_answer(model, guess, choice1[i], choice2[i], choice3[i], choice4[i])\n",
    "            if choice == answer:\n",
    "                correct_guesses += 1\n",
    "                label = 'correct'\n",
    "            else:\n",
    "                label = 'wrong'\n",
    "        else: \n",
    "            choice = random_guess(choice1[i], choice2[i], choice3[i], choice4[i])\n",
    "            random_guesses += 1\n",
    "            label = 'guess'\n",
    "        \n",
    "        with open(model_name, 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            row = [question, answer, choice, label]\n",
    "            writer.writerow(row)\n",
    "    return correct_guesses, random_guesses\n",
    "\n",
    "def write_model_analysis(model_name, size_of_vocab, number_of_correct, number_of_non_random_guess, accuracy):\n",
    "    with open('analysis.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        row = [model_name, size_of_vocab, number_of_correct, number_of_non_random_guess, accuracy]\n",
    "        writer.writerow(row)\n",
    "\n",
    "# Analysis\n",
    "with open('analysis.csv', 'w+') as f:\n",
    "    writer = csv.writer(f)\n",
    "    field = ['model_name', 'size_of_vocab', 'number_of_correct', 'number_of_non_random_guess', 'accuracy']\n",
    "    writer.writerow(field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Evaluation of the word2vec-google-news-300 Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec gooogle news model\n",
    "wv_google = api.load('word2vec-google-news-300')\n",
    "file_name_0 = 'word2vec-google-news-300.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "df = pd.read_csv('synonym.csv')\n",
    "questions = df['question'].tolist()\n",
    "answers = df['answer'].tolist()\n",
    "\n",
    "choice1 = df['0'].tolist()\n",
    "choice2 = df['1'].tolist()\n",
    "choice3 = df['2'].tolist()\n",
    "choice4 = df['3'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Guessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model guessing the correct answers\n",
    "create_model_details(file_name_0)\n",
    "correct_guesses_google300, random_guesses_google300 = test_model(file_name_0, wv_google, questions, answers, choice1, choice2, choice3, choice4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec google news 300 model\n",
    "model_name_google300 = 'word2vec-google-news-300'\n",
    "size_of_vocab_google300 = len(wv_google.key_to_index)\n",
    "number_of_correct_google300 = correct_guesses_google300\n",
    "number_of_non_random_guess = len(questions) - random_guesses_google300\n",
    "accuracy_google300 = correct_guesses_google300 / number_of_non_random_guess\n",
    "\n",
    "write_model_analysis(model_name_google300, size_of_vocab_google300, number_of_correct_google300, number_of_non_random_guess, accuracy_google300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Comparison with other pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 2 new models from different corpora but same embedding size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "glove-twitter-200 <br>\n",
    "glove-wiki-gigaword-300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_twitter200 = api.load('glove-twitter-200')\n",
    "file_name_1 = 'glove-twitter-200.csv'\n",
    "\n",
    "glove_wiki200 = api.load('glove-wiki-gigaword-200')\n",
    "file_name_2 = 'glove-wiki-gigaword-200.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glove twitter 200 model guessing and analytics\n",
    "create_model_details(file_name_1)\n",
    "correct_guesses_twitter200, random_guesses_twitter200 = test_model(file_name_1, glove_twitter200, questions, answers, choice1, choice2, choice3, choice4)\n",
    "\n",
    "model_name_twitter200 = 'glove-twitter-200'\n",
    "size_of_vocab_twitter200 = len(glove_twitter200.key_to_index)\n",
    "number_of_correct_twitter200 = correct_guesses_twitter200\n",
    "number_of_non_random_guess_twitter200 = len(questions) - random_guesses_twitter200\n",
    "accuracy_twitter200 = correct_guesses_twitter200 / number_of_non_random_guess_twitter200\n",
    "\n",
    "write_model_analysis(model_name_twitter200, size_of_vocab_twitter200, number_of_correct_twitter200, number_of_non_random_guess_twitter200, accuracy_twitter200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glove wiki 200 model guessing and analytics\n",
    "create_model_details(file_name_2)\n",
    "correct_guesses_wiki200, random_guesses_wiki200 = test_model(file_name_2, glove_wiki200, questions, answers, choice1, choice2, choice3, choice4)\n",
    "\n",
    "model_name_wiki200 = 'glove-wiki-200'\n",
    "size_of_vocab_wiki200 = len(glove_wiki200.key_to_index)\n",
    "number_of_correct_wiki200 = correct_guesses_wiki200\n",
    "number_of_non_random_guess_wiki200 = len(questions) - random_guesses_wiki200\n",
    "accuracy_wiki200 = correct_guesses_wiki200 / number_of_non_random_guess_wiki200\n",
    "\n",
    "write_model_analysis(model_name_wiki200, size_of_vocab_wiki200, number_of_correct_wiki200, number_of_non_random_guess_wiki200, accuracy_wiki200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 2 new models with different embdedding size but same corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "glove-twitter-50 <br>\n",
    "glove-twitter-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 387.1/387.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "glove_twitter50 = api.load('glove-twitter-50')\n",
    "file_name_3 = 'glove-twitter-50.csv'\n",
    "\n",
    "glove_twitter100 = api.load('glove-twitter-100')\n",
    "file_name_4 = 'glove-twitter-100.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glove twitter 50 model guessing and analytics\n",
    "create_model_details(file_name_3)\n",
    "correct_guesses_twitter50, random_guesses_twitter50 = test_model(file_name_3, glove_twitter50, questions, answers, choice1, choice2, choice3, choice4)\n",
    "\n",
    "model_name_twitter50 = 'glove-twitter-50'\n",
    "size_of_vocab_twitter50 = len(glove_twitter50.key_to_index)\n",
    "number_of_correct_twitter50 = correct_guesses_twitter50\n",
    "number_of_non_random_guess_twitter50 = len(questions) - random_guesses_twitter50\n",
    "accuracy_twitter50 = correct_guesses_twitter50 / number_of_non_random_guess_twitter50\n",
    "\n",
    "write_model_analysis(model_name_twitter50, size_of_vocab_twitter50, number_of_correct_twitter50, number_of_non_random_guess_twitter50, accuracy_twitter50)\n",
    "\n",
    "# Glove twitter 100 model guessing and analytics\n",
    "create_model_details(file_name_4)\n",
    "correct_guesses_twitter100, random_guesses_twitter100 = test_model(file_name_4, glove_twitter100, questions, answers, choice1, choice2, choice3, choice4)\n",
    "\n",
    "model_name_twitter100 = 'glove-twitter-100'\n",
    "size_of_vocab_twitter100 = len(glove_twitter100.key_to_index)\n",
    "number_of_correct_twitter100 = correct_guesses_twitter100\n",
    "number_of_non_random_guess_twitter100 = len(questions) - random_guesses_twitter100\n",
    "accuracy_twitter100 = correct_guesses_twitter100 / number_of_non_random_guess_twitter100\n",
    "\n",
    "write_model_analysis(model_name_twitter100, size_of_vocab_twitter100, number_of_correct_twitter100, number_of_non_random_guess_twitter100, accuracy_twitter100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Train own models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
