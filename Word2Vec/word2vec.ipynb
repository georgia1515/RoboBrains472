{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "import csv\n",
    "import random\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods\n",
    "def select_answer(model, guess, choice1, choice2, choice3, choice4):\n",
    "    choices = [choice1, choice2, choice3, choice4]\n",
    "    if choice1 in model:\n",
    "        choice1_similarity = model.similarity(guess, choice1)\n",
    "    else:\n",
    "        choice1_similarity = 0\n",
    "    \n",
    "    if choice2 in model:\n",
    "        choice2_similarity = model.similarity(guess, choice2)\n",
    "    else:\n",
    "        choice2_similarity = 0\n",
    "    \n",
    "    if choice3 in model:\n",
    "        choice3_similarity = model.similarity(guess, choice3)\n",
    "    else:\n",
    "        choice3_similarity = 0\n",
    "    \n",
    "    if choice4 in model:\n",
    "        choice4_similarity = model.similarity(guess, choice4)\n",
    "    else:\n",
    "        choice4_similarity = 0\n",
    "    \n",
    "    similarity = [choice1_similarity, choice2_similarity, choice3_similarity, choice4_similarity]\n",
    "    \n",
    "    answer = similarity.index(max(similarity))\n",
    "    final_choice = choices[answer]\n",
    "    return final_choice\n",
    "\n",
    "def random_guess(choice1, choice2, choice3, choice4):\n",
    "    choices = [choice1, choice2, choice3, choice4]\n",
    "    return choices[random.randint(0,3)]\n",
    "\n",
    "def create_model_details(model_name):\n",
    "    with open(model_name, 'w+') as f:\n",
    "        writer = csv.writer(f)\n",
    "        field = ['question', 'answer', 'guess', 'label']\n",
    "        writer.writerow(field)\n",
    "\n",
    "def test_model(model_name, model, questions, answers, choice1, choice2, choice3, choice4):\n",
    "    correct_guesses = 0\n",
    "    random_guesses = 0\n",
    "\n",
    "    for i in range(len(questions)):\n",
    "        question = questions[i]\n",
    "        answer = answers[i]\n",
    "        \n",
    "        if question in model:\n",
    "            guess = model.most_similar(question)[0][0]\n",
    "            choice = select_answer(model, guess, choice1[i], choice2[i], choice3[i], choice4[i])\n",
    "            if choice == answer:\n",
    "                correct_guesses += 1\n",
    "                label = 'correct'\n",
    "            else:\n",
    "                label = 'wrong'\n",
    "        else: \n",
    "            choice = random_guess(choice1[i], choice2[i], choice3[i], choice4[i])\n",
    "            random_guesses += 1\n",
    "            label = 'guess'\n",
    "        \n",
    "        with open(model_name, 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            row = [question, answer, choice, label]\n",
    "            writer.writerow(row)\n",
    "    return correct_guesses, random_guesses\n",
    "\n",
    "def write_model_analysis(model_name, size_of_vocab, number_of_correct, number_of_non_random_guess, accuracy):\n",
    "    with open('analysis.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        row = [model_name, size_of_vocab, number_of_correct, number_of_non_random_guess, accuracy]\n",
    "        writer.writerow(row)\n",
    "\n",
    "# Analysis\n",
    "with open('analysis.csv', 'w+') as f:\n",
    "    writer = csv.writer(f)\n",
    "    field = ['model_name', 'size_of_vocab', 'number_of_correct', 'number_of_non_random_guess', 'accuracy']\n",
    "    writer.writerow(field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Evaluation of the word2vec-google-news-300 Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec gooogle news model\n",
    "wv_google = api.load('word2vec-google-news-300')\n",
    "file_name_0 = 'word2vec-google-news-300.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "df = pd.read_csv('synonym.csv')\n",
    "questions = df['question'].tolist()\n",
    "answers = df['answer'].tolist()\n",
    "\n",
    "choice1 = df['0'].tolist()\n",
    "choice2 = df['1'].tolist()\n",
    "choice3 = df['2'].tolist()\n",
    "choice4 = df['3'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Guessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model guessing the correct answers\n",
    "create_model_details(file_name_0)\n",
    "correct_guesses_google300, random_guesses_google300 = test_model(file_name_0, wv_google, questions, answers, choice1, choice2, choice3, choice4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec google news 300 model\n",
    "model_name_google300 = 'word2vec-google-news-300'\n",
    "size_of_vocab_google300 = len(wv_google.key_to_index)\n",
    "number_of_correct_google300 = correct_guesses_google300\n",
    "number_of_non_random_guess = len(questions) - random_guesses_google300\n",
    "accuracy_google300 = correct_guesses_google300 / number_of_non_random_guess\n",
    "\n",
    "write_model_analysis(model_name_google300, size_of_vocab_google300, number_of_correct_google300, number_of_non_random_guess, accuracy_google300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Comparison with other pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 2 new models from different corpora but same embedding size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "glove-twitter-200 <br>\n",
    "glove-wiki-gigaword-300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_twitter200 = api.load('glove-twitter-200')\n",
    "file_name_1 = 'glove-twitter-200.csv'\n",
    "\n",
    "glove_wiki200 = api.load('glove-wiki-gigaword-200')\n",
    "file_name_2 = 'glove-wiki-gigaword-200.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glove twitter 200 model guessing and analytics\n",
    "create_model_details(file_name_1)\n",
    "correct_guesses_twitter200, random_guesses_twitter200 = test_model(file_name_1, glove_twitter200, questions, answers, choice1, choice2, choice3, choice4)\n",
    "\n",
    "model_name_twitter200 = 'glove-twitter-200'\n",
    "size_of_vocab_twitter200 = len(glove_twitter200.key_to_index)\n",
    "number_of_correct_twitter200 = correct_guesses_twitter200\n",
    "number_of_non_random_guess_twitter200 = len(questions) - random_guesses_twitter200\n",
    "accuracy_twitter200 = correct_guesses_twitter200 / number_of_non_random_guess_twitter200\n",
    "\n",
    "write_model_analysis(model_name_twitter200, size_of_vocab_twitter200, number_of_correct_twitter200, number_of_non_random_guess_twitter200, accuracy_twitter200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glove wiki 200 model guessing and analytics\n",
    "create_model_details(file_name_2)\n",
    "correct_guesses_wiki200, random_guesses_wiki200 = test_model(file_name_2, glove_wiki200, questions, answers, choice1, choice2, choice3, choice4)\n",
    "\n",
    "model_name_wiki200 = 'glove-wiki-200'\n",
    "size_of_vocab_wiki200 = len(glove_wiki200.key_to_index)\n",
    "number_of_correct_wiki200 = correct_guesses_wiki200\n",
    "number_of_non_random_guess_wiki200 = len(questions) - random_guesses_wiki200\n",
    "accuracy_wiki200 = correct_guesses_wiki200 / number_of_non_random_guess_wiki200\n",
    "\n",
    "write_model_analysis(model_name_wiki200, size_of_vocab_wiki200, number_of_correct_wiki200, number_of_non_random_guess_wiki200, accuracy_wiki200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 2 new models with different embdedding size but same corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "glove-twitter-50 <br>\n",
    "glove-twitter-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_twitter50 = api.load('glove-twitter-50')\n",
    "file_name_3 = 'glove-twitter-50.csv'\n",
    "\n",
    "glove_twitter100 = api.load('glove-twitter-100')\n",
    "file_name_4 = 'glove-twitter-100.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glove twitter 50 model guessing and analytics\n",
    "create_model_details(file_name_3)\n",
    "correct_guesses_twitter50, random_guesses_twitter50 = test_model(file_name_3, glove_twitter50, questions, answers, choice1, choice2, choice3, choice4)\n",
    "\n",
    "model_name_twitter50 = 'glove-twitter-50'\n",
    "size_of_vocab_twitter50 = len(glove_twitter50.key_to_index)\n",
    "number_of_correct_twitter50 = correct_guesses_twitter50\n",
    "number_of_non_random_guess_twitter50 = len(questions) - random_guesses_twitter50\n",
    "accuracy_twitter50 = correct_guesses_twitter50 / number_of_non_random_guess_twitter50\n",
    "\n",
    "write_model_analysis(model_name_twitter50, size_of_vocab_twitter50, number_of_correct_twitter50, number_of_non_random_guess_twitter50, accuracy_twitter50)\n",
    "\n",
    "# Glove twitter 100 model guessing and analytics\n",
    "create_model_details(file_name_4)\n",
    "correct_guesses_twitter100, random_guesses_twitter100 = test_model(file_name_4, glove_twitter100, questions, answers, choice1, choice2, choice3, choice4)\n",
    "\n",
    "model_name_twitter100 = 'glove-twitter-100'\n",
    "size_of_vocab_twitter100 = len(glove_twitter100.key_to_index)\n",
    "number_of_correct_twitter100 = correct_guesses_twitter100\n",
    "number_of_non_random_guess_twitter100 = len(questions) - random_guesses_twitter100\n",
    "accuracy_twitter100 = correct_guesses_twitter100 / number_of_non_random_guess_twitter100\n",
    "\n",
    "write_model_analysis(model_name_twitter100, size_of_vocab_twitter100, number_of_correct_twitter100, number_of_non_random_guess_twitter100, accuracy_twitter100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Train own models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rck20\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "books = ['book1_theakkracase.txt', 'book2_aliceinwonderland.txt', 'book3_thepictureofdoriangray.txt', 'book4_theadventuresofsherlockholmes.txt', 'book5_thegreatgatsby.txt', 'book6_modestproposal.txt', 'book7_metamorphosis.txt']\n",
    "book_sentences = {}\n",
    "\n",
    "for book in books:\n",
    "    with open(book, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        sentences = sent_tokenize(text)\n",
    "        # print(sentences[0])\n",
    "        book_sentences[book] = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "\n",
    "\n",
    "flat_list = [item for sublist in book_sentences.values() for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different window size 5 and 10\n",
    "model_5_100 = Word2Vec(flat_list, window=5, vector_size=100, workers=4)\n",
    "model_10_100 = Word2Vec(flat_list, window=10, vector_size=100, workers=4)\n",
    "# print(model_5_100.wv.key_to_index)\n",
    "# print(len(model_5_100.wv.key_to_index))\n",
    "\n",
    "file_name_5_100 = 'own_corpus_5_100.csv'\n",
    "file_name_10_100 = 'own_corpus_10_100.csv'\n",
    "\n",
    "# Own corpus window size 5 and 10 model guessing and analytics\n",
    "# Corpus 5 100\n",
    "create_model_details(file_name_5_100)\n",
    "correct_guesses_5_100, random_guesses_5_100 = test_model(file_name_5_100, model_5_100.wv, questions, answers, choice1, choice2, choice3, choice4)\n",
    "\n",
    "model_name_5_100 = 'own_corpus_5_100'\n",
    "size_of_vocab_5_100 = len(model_5_100.wv.key_to_index)\n",
    "number_of_correct_5_100 = correct_guesses_5_100\n",
    "number_of_non_random_guess_5_100 = len(questions) - random_guesses_5_100\n",
    "accuracy_5_100 = correct_guesses_5_100 / number_of_non_random_guess_5_100\n",
    "\n",
    "write_model_analysis(model_name_5_100, size_of_vocab_5_100, number_of_correct_5_100, number_of_non_random_guess_5_100, accuracy_5_100)\n",
    "\n",
    "#  Corpus 10 100\n",
    "create_model_details(file_name_10_100)\n",
    "correct_guesses_10_100, random_guesses_10_100 = test_model(file_name_10_100, model_10_100.wv, questions, answers, choice1, choice2, choice3, choice4)\n",
    "\n",
    "model_name_10_100 = 'own_corpus_10_100'\n",
    "size_of_vocab_10_100 = len(model_10_100.wv.key_to_index)\n",
    "number_of_correct_10_100 = correct_guesses_10_100\n",
    "number_of_non_random_guess_10_100 = len(questions) - random_guesses_10_100\n",
    "accuracy_10_100 = correct_guesses_10_100 / number_of_non_random_guess_10_100\n",
    "\n",
    "write_model_analysis(model_name_10_100, size_of_vocab_10_100, number_of_correct_10_100, number_of_non_random_guess_10_100, accuracy_10_100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different embedding size 100 and 200\n",
    "model_10_300 = Word2Vec(flat_list, window=10, vector_size=300, workers=4)\n",
    "model_10_200 = Word2Vec(flat_list, window=10, vector_size=200, workers=4)\n",
    "\n",
    "file_name_10_300 = 'own_corpus_10_300.csv'\n",
    "file_name_10_200 = 'own_corpus_10_200.csv'\n",
    "\n",
    "# Own corpus embedding size 300 and 200 model guessing and analytics\n",
    "# Corpus 10 300\n",
    "create_model_details(file_name_10_300)\n",
    "correct_guesses_10_300, random_guesses_10_300 = test_model(file_name_10_300, model_10_300.wv, questions, answers, choice1, choice2, choice3, choice4)\n",
    "\n",
    "model_name_10_300 = 'own_corpus_10_300'\n",
    "size_of_vocab_10_300 = len(model_10_300.wv.key_to_index)\n",
    "number_of_correct_10_300 = correct_guesses_10_300\n",
    "number_of_non_random_guess_10_300 = len(questions) - random_guesses_10_300\n",
    "accuracy_10_300 = correct_guesses_10_300 / number_of_non_random_guess_10_300\n",
    "\n",
    "write_model_analysis(model_name_10_300, size_of_vocab_10_300, number_of_correct_10_300, number_of_non_random_guess_10_300, accuracy_10_300)\n",
    "\n",
    "# Corpus 10 200\n",
    "create_model_details(file_name_10_200)\n",
    "correct_guesses_10_200, random_guesses_10_200 = test_model(file_name_10_200, model_10_200.wv, questions, answers, choice1, choice2, choice3, choice4)\n",
    "\n",
    "model_name_10_200 = 'own_corpus_10_200'\n",
    "size_of_vocab_10_200 = len(model_10_200.wv.key_to_index)\n",
    "number_of_correct_10_200 = correct_guesses_10_200\n",
    "number_of_non_random_guess_10_200 = len(questions) - random_guesses_10_200\n",
    "accuracy_10_200 = correct_guesses_10_200 / number_of_non_random_guess_10_200\n",
    "\n",
    "write_model_analysis(model_name_10_200, size_of_vocab_10_200, number_of_correct_10_200, number_of_non_random_guess_10_200, accuracy_10_200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
